# Phoenix：推荐系统

本仓库包含 Phoenix 推荐系统的 JAX 示例代码，该系统驱动内容排序和检索。Phoenix 使用基于 Transformer 的架构来实现**检索**（从数百万项中查找相关候选）和**排序**（通过预测的交互对较小的候选集进行排序）。

> **注意：** 本仓库中的示例 Transformer 实现移植自 xAI 的 [Grok-1 开源版本](https://github.com/xai-org/grok-1)。核心 Transformer 架构来自 Grok-1，在此针对推荐系统用例进行了适配，包括自定义输入嵌入和用于候选隔离的注意力掩码。此代码代表了内部使用的模型，但排除了特定的扩展优化。

## 目录

- [概述](#概述)
- [架构](#架构)
  - [两阶段推荐管道](#两阶段推荐管道)
  - [检索：Two-Tower 模型](#检索two-tower-模型)
  - [排序：带候选隔离的 Transformer](#排序带候选隔离的-transformer)
- [关键设计决策](#关键设计决策)
- [运行代码](#运行代码)
- [许可证](#许可证)

---

## 概述

Phoenix 是一个推荐系统，预测用户对内容的交互（点赞、转发、回复等）。它分两个阶段运行：

1. **检索**：使用近似最近邻（ANN）搜索，高效地将数百万候选缩小到数百个
2. **排序**：使用更具表达力的 Transformer 模型对检索到的候选进行打分和排序

---

## 架构

### 两阶段推荐管道

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           推荐管道                                               │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│   ┌──────────┐     ┌─────────────────────┐     ┌─────────────────────┐          │
│   │          │     │                     │     │                     │          │
│   │  用户    │────▶│   阶段1：           │────▶│   阶段2：           │────▶ Feed│
│   │  请求    │     │   检索              │     │   排序              │          │
│   │          │     │   (Two-Tower)       │     │   (Transformer)     │          │
│   └──────────┘     │                     │     │                     │          │
│                    │   百万级 → 数千个   │     │   数千个 → 排序后    │          │
│                    └─────────────────────┘     └─────────────────────┘          │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

### 检索：Two-Tower 模型

检索阶段使用**双塔架构**，实现大规模的高效相似度搜索。

#### 检索如何工作

1. **User Tower（用户塔）**：通过 Transformer 将用户特征和交互历史编码为归一化的用户嵌入 `[B, D]`
2. **Candidate Tower（候选塔）**：计算语料库中所有项的归一化嵌入 `[N, D]`
3. **相似度搜索**：使用点积相似度检索 Top-K 候选

---

### 排序：带候选隔离的 Transformer

排序模型使用 Transformer 架构，在推理期间**候选之间不能相互关注**。这是一个关键的设计选择，确保候选的分数不依赖于批次中的其他候选。

#### 排序模型架构

```
                              PHOENIX 排序模型
    ┌────────────────────────────────────────────────────────────────────────────┐
    │                                                                            │
    │                              输出逻辑值                                    │
    │                        [B, num_candidates, num_actions]                    │
    │                                    │                                       │
    │                                    │ 反嵌入                                 │
    │                                    │ 投影                                   │
    │                                    │                                       │
    │                    ┌───────────────┴───────────────┐                       │
    │                    │                               │                       │
    │                    │    提取候选输出               │                       │
    │                    │    (历史之后的位置)            │                       │
    │                    │                               │                       │
    │                    └───────────────┬───────────────┘                       │
    │                                    │                                       │
    │                    ┌───────────────┴───────────────┐                       │
    │                    │                               │                       │
    │                    │         Transformer           │                       │
    │                    │     (带特殊掩码)              │                       │
    │                    │                               │                       │
    │                    │   候选之间不能相互关注         │                       │
    │                    │                               │                       │
    │                    └───────────────┬───────────────┘                       │
    │                                    │                                       │
    │    ┌───────────────────────────────┼───────────────────────────────┐       │
    │    │                               │                               │       │
    │    ▼                               ▼                               ▼       │
    │ ┌──────────┐              ┌─────────────────┐              ┌────────────┐  │
    │ │  用户    │              │     历史         │              │  候选      │  │
    │ │嵌入      │              │   嵌入          │              │  嵌入      │  │
    │ │  [B, 1]  │              │    [B, S, D]    │              │  [B, C, D] │  │
    │ │          │              │                 │              │            │  │
    │ │ 用户     │              │ 帖子 + 作者     │              │ 帖子 +    │  │
    │ │ 哈希     │              │ + 动作 +        │              │ 作者 +    │  │
    │ │          │              │ 产品表面        │              │ 产品      │  │
    │ └──────────┘              └─────────────────┘              │ 表面      │  │
    │                                                            └────────────┘  │
    │                                                                            │
    └────────────────────────────────────────────────────────────────────────────┘
```

#### 注意力掩码：候选隔离

一个关键细节是**注意力掩码**，它防止候选之间相互关注，同时仍允许它们关注用户和历史：

```
                    注意力掩码可视化

         Keys (我们关注的内容)
         ─────────────────────────────────────────────▶

         │ 用户 │    历史 (S 个位置)    │   候选 (C 个位置)    │
    ┌────┼──────┼─────────────────────────┼───────────────────────┤
    │    │      │                         │                       │
    │ U  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✗   ✗    │
    │    │      │                         │                       │
    ├────┼──────┼─────────────────────────┼───────────────────────┤
 Q  │    │      │                         │                       │
 u  │ H  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✗   ✗    │
 e  │ i  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✗   ✗    │
 r  │ s  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✗   ✗    │
 i  │ t  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✗   ✗    │
 e  │    │      │                         │                       │
 s  ├────┼──────┼─────────────────────────┼───────────────────────┤
    │    │      │                         │  仅对角线（自关注）    │
 │  │ C  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✓   ✗   ✗   ✗   ✗   ✗    │
 │  │ a  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✓   ✗   ✗   ✗   ✗    │
 │  │ n  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✓   ✗   ✗   ✗    │
 │  │ d  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✓   ✗   ✗    │
 │  │ i  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✓   ✗    │
 │  │ d  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✗   ✓    │
 ▼  │ s  │  ✓   │  ✓   ✓   ✓   ✓   ✓   ✓  │  ✗   ✗   ✗   ✗   ✗   ✗    │
    │    │      │                         │                       │
    └────┴──────┴─────────────────────────┴───────────────────────┘

    ✓ = 可以关注 (1)          ✗ = 不能关注 (0)

    图例：
    ├─ 用户 + 历史：它们之间完全双向关注
    ├─ 候选 → 用户/历史：候选可以关注用户和历史  
    └─ 候选 → 候选：候选之间不能相互关注（仅自关注）
```

---

## 关键设计决策

### 1. 基于哈希的嵌入

两个模型都使用多个哈希函数进行嵌入查找

### 2. 共享架构

检索用户塔使用与排序模型相同的 Transformer 架构

### 3. 多动作预测

排序模型同时预测多种交互类型：

```
输出: [B, num_candidates, num_actions]
                              │
                              ▼
        ┌─────────────────────────────────────┐
        │ 点赞 │ 转发 │ 回复 │ 点击 │ ... │
        └─────────────────────────────────────┘
```

---

## 运行代码

### 安装

安装 [uv](https://docs.astral.sh/uv/getting-started/installation/)

### 运行排序器

```shell
uv run run_ranker.py
```

### 运行检索

```shell
uv run run_retrieval.py
```

### 运行测试

```shell
uv run pytest test_recsys_model.py test_recsys_retrieval_model.py
```

---

## 许可证

本项目采用 Apache License 2.0 许可证。详情请参见 [LICENSE](../LICENSE) 文件。
